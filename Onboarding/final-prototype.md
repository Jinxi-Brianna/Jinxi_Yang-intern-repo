## Reflection: Testing & Iterating on Prototypes

### Q1. How can UX designers balance design vision vs. user feedback when making iterations?

Balancing design vision with user feedback requires understanding the intent behind both. A UX designer should preserve the core design principles and brand direction while remaining flexible to user needs. When feedback challenges a design element, the designer should evaluate whether the suggestion improves usability or conflicts with the intended experience. It helps to use evidence from usability testing to justify decisions, rather than changing designs reactively. Maintaining a clear design rationale and using feedback as a guide—not as an order—allows designers to evolve their work without losing coherence or purpose.

---

### Q2. If conflicting feedback arises, how would you decide what to change?

When feedback conflicts, prioritization becomes essential. The first step is to identify which feedback source aligns most closely with user goals and project objectives. Quantitative usability data should take precedence over subjective opinions, and repeated issues across multiple users should be prioritized. Designers can use frameworks like the MoSCoW method to categorize changes as “Must,” “Should,” or “Could” have. Engaging stakeholders and developers in short review sessions can also clarify technical and business constraints, ensuring that iterations remain both user-centered and feasible.

---

### Q3. What are the risks of iterating too much without clear direction?

Excessive iteration without a clear goal can lead to overdesign and decision fatigue. When designers continuously refine visuals or micro-interactions without new insights, they risk wasting time, introducing inconsistencies, or drifting away from the validated user flow. Each round of iteration should have a defined objective based on testing outcomes or design hypotheses. Establishing clear success criteria and version control ensures that iteration remains purposeful and contributes to measurable improvement rather than endless refinement.

---

## Task: Usability Testing and Iteration Summary

**Prototype Tested:** Onboarding / Time Setting Flow (High-Fidelity Version)  
**Testing Participants:** 2 colleagues (UX designer and QA tester)  
**Date Conducted:** September 18, 2025  

### Key Findings
- **Issue 1:** Participants found the popup design inconsistent with the rest of the onboarding flow.  
  **Iteration:** Replaced popup with a full-screen layout aligned with the existing onboarding template.  
- **Issue 2:** Text on the “Set Tech Curfew” screen felt slightly overwhelming.  
  **Iteration:** Simplified the copy and increased heading hierarchy to improve scannability.  
- **Issue 3:** The time picker transition appeared abrupt.  
  **Iteration:** Added a short 200ms ease-out transition for smoother interaction.  
- **Issue 4:** One participant asked whether the selected time syncs with other devices.  
  **Iteration:** Added a short confirmation message explaining that sync happens automatically.

### Outcome
The revised prototype was re-tested with the same participants and received positive feedback for clarity and consistency. Both testers reported smoother navigation and better comprehension of the time-setting process. The design was approved for the final review by the supervisor and marked as developer-ready.

> Supporting files:
> (https://www.figma.com/design/E6ChDtYlZPsFndZPkRIrGA/Onboarding?node-id=75-31&t=CC4Jbm2Vvc2kmIBK-1)
